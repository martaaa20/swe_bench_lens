## Qwen3-Coder-30B-A3B-Instruct

Qwen3-Coder is available in multiple sizes. Today, we're excited to introduce Qwen3-Coder-30B-A3B-Instruct. This streamlined model maintains impressive performance and efficiency, featuring the following key enhancements:

- Significant Performance among open models on Agentic Coding, Agentic Browser-Use, and other foundational coding tasks.

- Long-context Capabilities with native support for 256K tokens, extendable up to 1M tokens using Yarn, optimized for repository-scale understanding.

- Agentic Coding supporting for most platform such as Qwen Code, CLINE, featuring a specially designed function call format.

Blog: https://qwenlm.github.io/blog/qwen3-coder/

## Performance

```md
Submission summary for 20250805-openhands-Qwen3-Coder-30B-A3B-Instruct on SWE-bench verified split
==================================================
Resolved 258 instances (51.6%)
==================================================
Resolved by Repository
- astropy/astropy: 9/22 (40.91%)
- django/django: 125/231 (54.11%)
- matplotlib/matplotlib: 15/34 (44.12%)
- mwaskom/seaborn: 0/2 (0.0%)
- pallets/flask: 1/1 (100.0%)
- psf/requests: 3/8 (37.5%)
- pydata/xarray: 13/22 (59.09%)
- pylint-dev/pylint: 2/10 (20.0%)
- pytest-dev/pytest: 9/19 (47.37%)
- scikit-learn/scikit-learn: 24/32 (75.0%)
- sphinx-doc/sphinx: 17/44 (38.64%)
- sympy/sympy: 40/75 (53.33%)
==================================================
Resolved by Time
- 2013: 2/3 (66.67%)
- 2014: 0/2 (0.0%)
- 2015: 1/1 (100.0%)
- 2016: 2/2 (100.0%)
- 2017: 9/16 (56.25%)
- 2018: 13/24 (54.17%)
- 2019: 56/98 (57.14%)
- 2020: 54/108 (50.0%)
- 2021: 39/86 (45.35%)
- 2022: 48/102 (47.06%)
- 2023: 34/58 (58.62%)
```


# Checklist

- [X] Is a pass@1 submission (does not attempt the same task instance more than once)
- [X] Does not use SWE-bench test knowledge (`PASS_TO_PASS`, `FAIL_TO_PASS`)
- [X] Does not use the `hints` field in SWE-bench
- [X] Does not have web-browsing OR has taken steps to prevent lookup of SWE-bench solutions via web-browsing
