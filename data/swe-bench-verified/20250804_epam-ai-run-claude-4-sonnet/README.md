# EPAM AI/Run Developer Agent

EPAM AI/Run Developer Agent is a coding assistant designed to help developers fix bugs and implement features more efficiently. Built on the proprietary EPAM AI/Run platform, it is part of a suite of agents aimed at automating the Software Development Lifecycle (SDLC). The agent operates in both conversational and autonomous modes, and for this benchmark, it was running fully autonomously.

Leveraging the CodeAct approach, the agent uses executable Python code as its unified action space, allowing for more flexible and powerful interactions with the development environment. This enables the agent to dynamically execute, revise, and generate new actions based on real-time observations and feedback. Under the hood, the agent leverages the advanced Claude 4 Sonnet model to build solutions and integrates with a file edit tool to produce actual patches.

The agent has been simplified compared to our previous submission. We no longer run unit testing or use multiple iterations per task, as Claude 4 Sonnet rarely produces regressions.

The agent now only retries when it cannot finalize the solution within the iteration limit, which indicates that it chose a wrong solution path. In such cases, the agent will retry the task up to 3 times to find a more efficient approach.

Read more about EPAM AI/Run: https://www.epam.com/services/artificial-intelligence

## Submission Checklist

- [X] Is a pass@1 submission (does not attempt the same task instance more than
  once)
- [X] Does not use SWE-bench test knowledge (`PASS_TO_PASS`, `FAIL_TO_PASS`)
- [X] Does not use the `hints` field in SWE-bench
- [X] Does not have web-browsing OR has taken steps to prevent lookup of
  SWE-bench solutions via web-browsing
